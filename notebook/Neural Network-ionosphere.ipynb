{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network - Ionosphere Dataset :-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Title of the data set: Ionosphere Data Set\n",
    "\n",
    "#### Number of instance: 351\n",
    "\n",
    "#### Number of attributes : 35 (34 predictive, 1 name)\n",
    "\n",
    "#### Dataset Information:\n",
    "This radar data was collected by a system in Goose Bay, Labrador. This system consists of a phased array of 16 high-frequency antennas with a total transmitted power on the order of 6.4 kilowatts. See the paper for more details. The targets were free electrons in the ionosphere. \"Good\" radar returns are those showing evidence of some type of structure in the ionosphere. \"Bad\" returns are those that do not; their signals pass through the ionosphere.\n",
    "\n",
    "Received signals were processed using an autocorrelation function whose arguments are the time of a pulse and the pulse number. There were 17 pulse numbers for the Goose Bay system. Instances in this databse are described by 2 attributes per pulse number, corresponding to the complex values returned by the function resulting from the complex electromagnetic signal.\n",
    "\n",
    "#### Attribute Information:\n",
    "-- All 34 are continuous\n",
    "-- The 35th attribute is either \"good\" or \"bad\" according to the definition summarized above. This is a binary classification task.\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imort data from data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Stuff\\KU Study\\EECS 738 Machine Learning\\Projects\\EECS738-Project-3---Says-One-Neuron-To-Another-\\data\\ionosphere.data', header=None, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>-0.09524</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.31746</td>\n",
       "      <td>...</td>\n",
       "      <td>0.36508</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.50794</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-0.32540</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.72831</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.08380</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.17387</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.13308</td>\n",
       "      <td>0.98172</td>\n",
       "      <td>0.64520</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.83899</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.74822</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.64358</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.52479</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5984</td>\n",
       "      <td>0.40332</td>\n",
       "      <td>0.82809</td>\n",
       "      <td>0.80521</td>\n",
       "      <td>0.76001</td>\n",
       "      <td>0.70709</td>\n",
       "      <td>0.84010</td>\n",
       "      <td>-0.10984</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.30063</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.17076</td>\n",
       "      <td>0.62958</td>\n",
       "      <td>0.42677</td>\n",
       "      <td>0.87757</td>\n",
       "      <td>0.81007</td>\n",
       "      <td>0.81979</td>\n",
       "      <td>0.68822</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0   1       2        3        4        5        6        7        8   \\\n",
       "194   1   0  1.0000 -0.09524 -1.00000 -1.00000 -1.00000 -1.00000  1.00000   \n",
       "28    1   0  1.0000  0.08380  1.00000  0.17387  1.00000 -0.13308  0.98172   \n",
       "79    0   0  1.0000  1.00000  1.00000 -1.00000  1.00000  1.00000 -1.00000   \n",
       "19    0   0  1.0000 -1.00000  0.00000  0.00000  0.00000  0.00000  1.00000   \n",
       "126   1   0  0.5984  0.40332  0.82809  0.80521  0.76001  0.70709  0.84010   \n",
       "\n",
       "          9   ...       25       26       27       28       29       30  \\\n",
       "194  0.31746  ...  0.36508  1.00000  1.00000  1.00000  0.50794 -1.00000   \n",
       "28   0.64520  ...  1.00000  0.83899  1.00000  0.74822  1.00000  0.64358   \n",
       "79   1.00000  ... -1.00000  1.00000  1.00000  1.00000  1.00000  1.00000   \n",
       "19   1.00000  ...  1.00000  1.00000  1.00000  1.00000 -1.00000  1.00000   \n",
       "126 -0.10984  ... -0.30063  1.00000  0.17076  0.62958  0.42677  0.87757   \n",
       "\n",
       "          31       32       33  34  \n",
       "194 -0.32540 -1.00000  0.72831   b  \n",
       "28   1.00000  0.52479  1.00000   g  \n",
       "79  -1.00000 -1.00000  1.00000   b  \n",
       "19   1.00000  1.00000  1.00000   b  \n",
       "126  0.81007  0.81979  0.68822   b  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking the Attribute values in X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99539</td>\n",
       "      <td>-0.05889</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>0.02306</td>\n",
       "      <td>0.83398</td>\n",
       "      <td>-0.37708</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.03760</td>\n",
       "      <td>...</td>\n",
       "      <td>0.56811</td>\n",
       "      <td>-0.51171</td>\n",
       "      <td>0.41078</td>\n",
       "      <td>-0.46168</td>\n",
       "      <td>0.21266</td>\n",
       "      <td>-0.34090</td>\n",
       "      <td>0.42267</td>\n",
       "      <td>-0.54487</td>\n",
       "      <td>0.18641</td>\n",
       "      <td>-0.45300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18829</td>\n",
       "      <td>0.93035</td>\n",
       "      <td>-0.36156</td>\n",
       "      <td>-0.10868</td>\n",
       "      <td>-0.93597</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.04549</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.20332</td>\n",
       "      <td>-0.26569</td>\n",
       "      <td>-0.20468</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.19040</td>\n",
       "      <td>-0.11593</td>\n",
       "      <td>-0.16626</td>\n",
       "      <td>-0.06288</td>\n",
       "      <td>-0.13738</td>\n",
       "      <td>-0.02447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.03365</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.88965</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>...</td>\n",
       "      <td>0.57528</td>\n",
       "      <td>-0.40220</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>-0.22145</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>-0.17365</td>\n",
       "      <td>0.60436</td>\n",
       "      <td>-0.24180</td>\n",
       "      <td>0.56045</td>\n",
       "      <td>-0.38238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.45161</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.71216</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.90695</td>\n",
       "      <td>0.51613</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.20099</td>\n",
       "      <td>0.25682</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.32382</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.02401</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.06531</td>\n",
       "      <td>0.92106</td>\n",
       "      <td>-0.23255</td>\n",
       "      <td>0.77152</td>\n",
       "      <td>-0.16399</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03286</td>\n",
       "      <td>-0.65158</td>\n",
       "      <td>0.13290</td>\n",
       "      <td>-0.53206</td>\n",
       "      <td>0.02431</td>\n",
       "      <td>-0.62197</td>\n",
       "      <td>-0.05707</td>\n",
       "      <td>-0.59573</td>\n",
       "      <td>-0.04608</td>\n",
       "      <td>-0.65697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.83508</td>\n",
       "      <td>0.08298</td>\n",
       "      <td>0.73739</td>\n",
       "      <td>-0.14706</td>\n",
       "      <td>0.84349</td>\n",
       "      <td>-0.05567</td>\n",
       "      <td>0.90441</td>\n",
       "      <td>-0.04622</td>\n",
       "      <td>...</td>\n",
       "      <td>0.95378</td>\n",
       "      <td>-0.04202</td>\n",
       "      <td>0.83479</td>\n",
       "      <td>0.00123</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.12815</td>\n",
       "      <td>0.86660</td>\n",
       "      <td>-0.10714</td>\n",
       "      <td>0.90546</td>\n",
       "      <td>-0.04307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.95113</td>\n",
       "      <td>0.00419</td>\n",
       "      <td>0.95183</td>\n",
       "      <td>-0.02723</td>\n",
       "      <td>0.93438</td>\n",
       "      <td>-0.01920</td>\n",
       "      <td>0.94590</td>\n",
       "      <td>0.01606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.94520</td>\n",
       "      <td>0.01361</td>\n",
       "      <td>0.93522</td>\n",
       "      <td>0.04925</td>\n",
       "      <td>0.93159</td>\n",
       "      <td>0.08168</td>\n",
       "      <td>0.94066</td>\n",
       "      <td>-0.00035</td>\n",
       "      <td>0.91483</td>\n",
       "      <td>0.04712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.94701</td>\n",
       "      <td>-0.00034</td>\n",
       "      <td>0.93207</td>\n",
       "      <td>-0.03227</td>\n",
       "      <td>0.95177</td>\n",
       "      <td>-0.03431</td>\n",
       "      <td>0.95584</td>\n",
       "      <td>0.02446</td>\n",
       "      <td>...</td>\n",
       "      <td>0.93988</td>\n",
       "      <td>0.03193</td>\n",
       "      <td>0.92489</td>\n",
       "      <td>0.02542</td>\n",
       "      <td>0.92120</td>\n",
       "      <td>0.02242</td>\n",
       "      <td>0.92459</td>\n",
       "      <td>0.00442</td>\n",
       "      <td>0.92697</td>\n",
       "      <td>-0.00577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.90608</td>\n",
       "      <td>-0.01657</td>\n",
       "      <td>0.98122</td>\n",
       "      <td>-0.01989</td>\n",
       "      <td>0.95691</td>\n",
       "      <td>-0.03646</td>\n",
       "      <td>0.85746</td>\n",
       "      <td>0.00110</td>\n",
       "      <td>...</td>\n",
       "      <td>0.91050</td>\n",
       "      <td>-0.02099</td>\n",
       "      <td>0.89147</td>\n",
       "      <td>-0.07760</td>\n",
       "      <td>0.82983</td>\n",
       "      <td>-0.17238</td>\n",
       "      <td>0.96022</td>\n",
       "      <td>-0.03757</td>\n",
       "      <td>0.87403</td>\n",
       "      <td>-0.16243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.84710</td>\n",
       "      <td>0.13533</td>\n",
       "      <td>0.73638</td>\n",
       "      <td>-0.06151</td>\n",
       "      <td>0.87873</td>\n",
       "      <td>0.08260</td>\n",
       "      <td>0.88928</td>\n",
       "      <td>-0.09139</td>\n",
       "      <td>...</td>\n",
       "      <td>0.86467</td>\n",
       "      <td>-0.15114</td>\n",
       "      <td>0.81147</td>\n",
       "      <td>-0.04822</td>\n",
       "      <td>0.78207</td>\n",
       "      <td>-0.00703</td>\n",
       "      <td>0.75747</td>\n",
       "      <td>-0.06678</td>\n",
       "      <td>0.85764</td>\n",
       "      <td>-0.06151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>351 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0   1        2        3        4        5        6        7        8   \\\n",
       "0     1   0  0.99539 -0.05889  0.85243  0.02306  0.83398 -0.37708  1.00000   \n",
       "1     1   0  1.00000 -0.18829  0.93035 -0.36156 -0.10868 -0.93597  1.00000   \n",
       "2     1   0  1.00000 -0.03365  1.00000  0.00485  1.00000 -0.12062  0.88965   \n",
       "3     1   0  1.00000 -0.45161  1.00000  1.00000  0.71216 -1.00000  0.00000   \n",
       "4     1   0  1.00000 -0.02401  0.94140  0.06531  0.92106 -0.23255  0.77152   \n",
       "..   ..  ..      ...      ...      ...      ...      ...      ...      ...   \n",
       "346   1   0  0.83508  0.08298  0.73739 -0.14706  0.84349 -0.05567  0.90441   \n",
       "347   1   0  0.95113  0.00419  0.95183 -0.02723  0.93438 -0.01920  0.94590   \n",
       "348   1   0  0.94701 -0.00034  0.93207 -0.03227  0.95177 -0.03431  0.95584   \n",
       "349   1   0  0.90608 -0.01657  0.98122 -0.01989  0.95691 -0.03646  0.85746   \n",
       "350   1   0  0.84710  0.13533  0.73638 -0.06151  0.87873  0.08260  0.88928   \n",
       "\n",
       "          9   ...       24       25       26       27       28       29  \\\n",
       "0    0.03760  ...  0.56811 -0.51171  0.41078 -0.46168  0.21266 -0.34090   \n",
       "1   -0.04549  ... -0.20332 -0.26569 -0.20468 -0.18401 -0.19040 -0.11593   \n",
       "2    0.01198  ...  0.57528 -0.40220  0.58984 -0.22145  0.43100 -0.17365   \n",
       "3    0.00000  ...  1.00000  0.90695  0.51613  1.00000  1.00000 -0.20099   \n",
       "4   -0.16399  ...  0.03286 -0.65158  0.13290 -0.53206  0.02431 -0.62197   \n",
       "..       ...  ...      ...      ...      ...      ...      ...      ...   \n",
       "346 -0.04622  ...  0.95378 -0.04202  0.83479  0.00123  1.00000  0.12815   \n",
       "347  0.01606  ...  0.94520  0.01361  0.93522  0.04925  0.93159  0.08168   \n",
       "348  0.02446  ...  0.93988  0.03193  0.92489  0.02542  0.92120  0.02242   \n",
       "349  0.00110  ...  0.91050 -0.02099  0.89147 -0.07760  0.82983 -0.17238   \n",
       "350 -0.09139  ...  0.86467 -0.15114  0.81147 -0.04822  0.78207 -0.00703   \n",
       "\n",
       "          30       31       32       33  \n",
       "0    0.42267 -0.54487  0.18641 -0.45300  \n",
       "1   -0.16626 -0.06288 -0.13738 -0.02447  \n",
       "2    0.60436 -0.24180  0.56045 -0.38238  \n",
       "3    0.25682  1.00000 -0.32382  1.00000  \n",
       "4   -0.05707 -0.59573 -0.04608 -0.65697  \n",
       "..       ...      ...      ...      ...  \n",
       "346  0.86660 -0.10714  0.90546 -0.04307  \n",
       "347  0.94066 -0.00035  0.91483  0.04712  \n",
       "348  0.92459  0.00442  0.92697 -0.00577  \n",
       "349  0.96022 -0.03757  0.87403 -0.16243  \n",
       "350  0.75747 -0.06678  0.85764 -0.06151  \n",
       "\n",
       "[351 rows x 34 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X= df.drop(df.columns[34], axis=1)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking the class information in Y. g represents good and b represents bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      g\n",
       "1      b\n",
       "2      g\n",
       "3      b\n",
       "4      g\n",
       "      ..\n",
       "346    g\n",
       "347    g\n",
       "348    g\n",
       "349    g\n",
       "350    g\n",
       "Name: 34, Length: 351, dtype: object"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y=df[34]\n",
    "#Y=Y.astype(float)\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using on_hot-encoding to code the class so that it can be converted in to a numerical value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "Y = one_hot_encoder.fit_transform(np.array(Y).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing the datatype of dataframe to numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 1, ..., 0, 0, 0],\n",
       "       [1, 0, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=X.astype(int)\n",
    "X = X.to_numpy()\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data set into train/validation/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.15)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation neural network.\n",
    "### Neural network consists of:\n",
    "        - An input layer, X\n",
    "        - Arbitary number of hidden layers\n",
    "        - An out put layer, Y\n",
    "        - A set of weights(W) and biases(B) between each layer\n",
    "        - A choice of activation function for each hidden layer, Ïƒ\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weight initialization is used to define the initial values for the parameters in neural network models prior to training the models on a dataset. We are going to initaialize the weight on the basis of nodes. The weights are initialized randomly between [-1,1]. The bias has a constant value = 1. Nodes are the list of integers and list of nodes denotes the number of layers. The function returns weights as a multi-dimensional array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Initialize_Weight(nodes):\n",
    "    layers, weights = len(nodes), []\n",
    "    \n",
    "    for i in range(1, layers):\n",
    "        wt = [[np.random.uniform(-1, 1) for k in range(nodes[i-1] + 1)] for j in range(nodes[i])]\n",
    "        weights.append(np.matrix(wt))\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural_Network function trains the network for given number of iterations. The input parameters are:\n",
    "        - training data and target values\n",
    "        - validation data and target values\n",
    "        - number of iterations , default=10\n",
    "        - list of integers\n",
    "        - learning rate of back-propagation algorithm, default=0.15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Neural_Network(X_train, Y_train, X_val=None, Y_val=None, iters=10, nodes=[], rate=0.15):\n",
    "    hiddenLayers = len(nodes) - 1\n",
    "    weights = Initialize_Weight(nodes)\n",
    "\n",
    "    for iter in range(1, iters+1):\n",
    "        weights = Train_Network(X_train, Y_train, rate, weights)\n",
    "\n",
    "        #Print the accuracy of training and validation after every 10 iterations\n",
    "        if(iter % 10 == 0):\n",
    "            print(\"Iteration {}\".format(iter))\n",
    "            print(\"Training Accuracy:{}\".format(accuracy(X_train, Y_train, weights)))\n",
    "            if X_val.any():\n",
    "                print(\"Validation Accuracy:{}\".format(accuracy(X_val, Y_val, weights)))\n",
    "                        \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forward_Propagation fucntion: Each layer receives an input and calculated the output by passing the dot product of input and weights of the layer to the Sigmoid function. The out of current layer is the input for the next layer. The output of last layer will be our prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Forward_Propagation(x, weights, layers):\n",
    "    output, current_input = [x], x\n",
    "\n",
    "    for j in range(layers):\n",
    "        activation = Sigmoid(np.dot(current_input, weights[j].T))\n",
    "        output.append(activation)\n",
    "        current_input = np.append(1, activation)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backward_Propagation Function: It propagates the error backwards and adjusts the weights. Delta is calculated as error of next layer times sigmoid derivation of the current layer's output. Weights between layers can be updated by adding weight of previous layer and output of previous layer with rate. Current layer's error can be calculated by removing bias from the weights of previous layer and then multiply it with delta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Backward_Propagation(y, output, weights, layers):\n",
    "    outputFinal = output[-1]\n",
    "    error = np.matrix(y - outputFinal) #Calculate the error at last output\n",
    "    \n",
    "    #Back propagate the error\n",
    "    for j in range(layers, 0, -1):\n",
    "        currOutput = output[j]\n",
    "        \n",
    "        if(j > 1):\n",
    "            # Adding previous output\n",
    "            prevOutput = np.append(1, output[j-1])\n",
    "        else:\n",
    "            prevOutput = output[0]\n",
    "        \n",
    "        delta = np.multiply(error, sigmoidDerivative(currOutput))\n",
    "        weights[j-1] += rate * np.multiply(delta.T, prevOutput)\n",
    "\n",
    "        wt = np.delete(weights[j-1], [0], axis=1) # Remove bias from weights\n",
    "        error = np.dot(delta, wt) # Calculate error for current layer\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train_Network: It will perform the forward and backward propagation based on teh inputs of X_train, Y-train, rate and weights. It will return the newly calculated weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train_Network(X, Y, rate, weights):\n",
    "    layers = len(weights)\n",
    "    for i in range(len(X)):\n",
    "        x = X[i]\n",
    "        y = Y[i]\n",
    "        x = np.matrix(np.append(1, x)) # Add feature vector\n",
    "        \n",
    "        output = Forward_Propagation(x, weights, layers)\n",
    "        weights = Backward_Propagation(y, output, weights, layers)\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activation Function : Sigmoid \n",
    "This function gives an output based on set of inputs for a node. The output generated for one node is used as input for the next node. This function decides which nodes can forward the output to the next layer. It outputs a value between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoidDerivative(x):\n",
    "    return np.multiply(x, 1-x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict fuction: In this funtion, the input is first passed to the Neural_network and then the result will have an array of values corresponding the the classes. The maximum value represent the likeliness of the class being predicted. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Predict(item, weights):\n",
    "    layers = len(weights)\n",
    "    item = np.append(1, item)\n",
    "    \n",
    "    #forward propagation\n",
    "    output = Forward_Propagation(item, weights, layers)\n",
    "    \n",
    "    outputFinal = output[-1].A1\n",
    "    index = findMax(outputFinal)\n",
    "\n",
    "    y = [0 for i in range(len(outputFinal))]\n",
    "    y[index] = 1\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "findMax() : It will find the maximum value in the array and then set corresponding index to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findMax(output):\n",
    "    m, index = output[0], 0\n",
    "    for i in range(1, len(output)):\n",
    "        if(output[i] > m):\n",
    "            m, index = output[i], i\n",
    "    \n",
    "    return index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy fuction: This will calculate the percentage of the predicted class against the actual class of the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(X, Y, weights):\n",
    "    correct_classification = 0\n",
    "\n",
    "    for i in range(len(X)):\n",
    "        x, y = X[i], list(Y[i])\n",
    "        prediction = Predict(x, weights)\n",
    "\n",
    "        if(y == prediction):\n",
    "            correct_classification += 1\n",
    "\n",
    "    return correct_classification / len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passing the features, classes, layers, rates and iterations to the Neural_Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10\n",
      "Training Accuracy:0.8395522388059702\n",
      "Validation Accuracy:0.8666666666666667\n",
      "Iteration 20\n",
      "Training Accuracy:0.8843283582089553\n",
      "Validation Accuracy:0.8666666666666667\n",
      "Iteration 30\n",
      "Training Accuracy:0.9104477611940298\n",
      "Validation Accuracy:0.8666666666666667\n",
      "Iteration 40\n",
      "Training Accuracy:0.9216417910447762\n",
      "Validation Accuracy:0.8333333333333334\n",
      "Iteration 50\n",
      "Training Accuracy:0.9216417910447762\n",
      "Validation Accuracy:0.8666666666666667\n",
      "Iteration 60\n",
      "Training Accuracy:0.9253731343283582\n",
      "Validation Accuracy:0.8666666666666667\n",
      "Iteration 70\n",
      "Training Accuracy:0.9328358208955224\n",
      "Validation Accuracy:0.9\n",
      "Iteration 80\n",
      "Training Accuracy:0.9328358208955224\n",
      "Validation Accuracy:0.9\n",
      "Iteration 90\n",
      "Training Accuracy:0.9328358208955224\n",
      "Validation Accuracy:0.9\n",
      "Iteration 100\n",
      "Training Accuracy:0.9328358208955224\n",
      "Validation Accuracy:0.9\n",
      "Iteration 110\n",
      "Training Accuracy:0.9365671641791045\n",
      "Validation Accuracy:0.9\n",
      "Iteration 120\n",
      "Training Accuracy:0.9365671641791045\n",
      "Validation Accuracy:0.9\n",
      "Iteration 130\n",
      "Training Accuracy:0.9365671641791045\n",
      "Validation Accuracy:0.9\n",
      "Iteration 140\n",
      "Training Accuracy:0.9365671641791045\n",
      "Validation Accuracy:0.9\n",
      "Iteration 150\n",
      "Training Accuracy:0.9365671641791045\n",
      "Validation Accuracy:0.9\n",
      "Iteration 160\n",
      "Training Accuracy:0.9365671641791045\n",
      "Validation Accuracy:0.8666666666666667\n",
      "Iteration 170\n",
      "Training Accuracy:0.9365671641791045\n",
      "Validation Accuracy:0.8666666666666667\n",
      "Iteration 180\n",
      "Training Accuracy:0.9365671641791045\n",
      "Validation Accuracy:0.9\n",
      "Iteration 190\n",
      "Training Accuracy:0.9365671641791045\n",
      "Validation Accuracy:0.9\n",
      "Iteration 200\n",
      "Training Accuracy:0.9365671641791045\n",
      "Validation Accuracy:0.9\n",
      "Iteration 210\n",
      "Training Accuracy:0.9365671641791045\n",
      "Validation Accuracy:0.9\n",
      "Iteration 220\n",
      "Training Accuracy:0.9365671641791045\n",
      "Validation Accuracy:0.9\n",
      "Iteration 230\n",
      "Training Accuracy:0.9365671641791045\n",
      "Validation Accuracy:0.9\n",
      "Iteration 240\n",
      "Training Accuracy:0.9365671641791045\n",
      "Validation Accuracy:0.9\n",
      "Iteration 250\n",
      "Training Accuracy:0.9365671641791045\n",
      "Validation Accuracy:0.9\n",
      "Iteration 260\n",
      "Training Accuracy:0.9365671641791045\n",
      "Validation Accuracy:0.9\n",
      "Iteration 270\n",
      "Training Accuracy:0.9365671641791045\n",
      "Validation Accuracy:0.9\n",
      "Iteration 280\n",
      "Training Accuracy:0.9365671641791045\n",
      "Validation Accuracy:0.9\n",
      "Iteration 290\n",
      "Training Accuracy:0.9365671641791045\n",
      "Validation Accuracy:0.9\n",
      "Iteration 300\n",
      "Training Accuracy:0.9365671641791045\n",
      "Validation Accuracy:0.9\n",
      "Iteration 310\n",
      "Training Accuracy:0.9365671641791045\n",
      "Validation Accuracy:0.9\n",
      "Iteration 320\n",
      "Training Accuracy:0.9365671641791045\n",
      "Validation Accuracy:0.9\n",
      "Iteration 330\n",
      "Training Accuracy:0.9365671641791045\n",
      "Validation Accuracy:0.9\n",
      "Iteration 340\n",
      "Training Accuracy:0.9365671641791045\n",
      "Validation Accuracy:0.9\n",
      "Iteration 350\n",
      "Training Accuracy:0.9365671641791045\n",
      "Validation Accuracy:0.9\n",
      "Iteration 360\n",
      "Training Accuracy:0.9365671641791045\n",
      "Validation Accuracy:0.9\n",
      "Iteration 370\n",
      "Training Accuracy:0.9365671641791045\n",
      "Validation Accuracy:0.9\n",
      "Iteration 380\n",
      "Training Accuracy:0.9365671641791045\n",
      "Validation Accuracy:0.9\n",
      "Iteration 390\n",
      "Training Accuracy:0.9365671641791045\n",
      "Validation Accuracy:0.9\n",
      "Iteration 400\n",
      "Training Accuracy:0.9365671641791045\n",
      "Validation Accuracy:0.9\n",
      "Iteration 410\n",
      "Training Accuracy:0.9365671641791045\n",
      "Validation Accuracy:0.9\n",
      "Iteration 420\n",
      "Training Accuracy:0.9365671641791045\n",
      "Validation Accuracy:0.9\n",
      "Iteration 430\n",
      "Training Accuracy:0.9365671641791045\n",
      "Validation Accuracy:0.9\n",
      "Iteration 440\n",
      "Training Accuracy:0.9365671641791045\n",
      "Validation Accuracy:0.9\n",
      "Iteration 450\n",
      "Training Accuracy:0.9365671641791045\n",
      "Validation Accuracy:0.9\n",
      "Iteration 460\n",
      "Training Accuracy:0.9365671641791045\n",
      "Validation Accuracy:0.9\n",
      "Iteration 470\n",
      "Training Accuracy:0.9365671641791045\n",
      "Validation Accuracy:0.9\n",
      "Iteration 480\n",
      "Training Accuracy:0.9365671641791045\n",
      "Validation Accuracy:0.9\n",
      "Iteration 490\n",
      "Training Accuracy:0.9365671641791045\n",
      "Validation Accuracy:0.9\n",
      "Iteration 500\n",
      "Training Accuracy:0.9365671641791045\n",
      "Validation Accuracy:0.9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "features = len(X[0])\n",
    "classes = len(Y[0]) \n",
    "layers = [features, 5, 10, classes]\n",
    "rate, iterations = 0.15, 100 #We are training the Neural_Network up to 100 iterations for this dataset as the accuracy converges after that\n",
    "\n",
    "weights = Neural_Network(X_train, Y_train, X_val, Y_val, iters=iterations, nodes=layers, rate=rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the accuracy after all the iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.8867924528301887\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing Accuracy: {}\".format(accuracy(X_test, Y_test, weights)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's predict an actual sample and get the predicted value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual:  [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [0.0, 1.0]\n",
      "Predicted:  [0, 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Actual: \",X_test[0], list(Y_test[0]))\n",
    "print(\"Predicted: \",Predict(X_test[0], weights))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
